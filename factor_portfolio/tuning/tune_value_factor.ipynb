{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Value Factor (Extensible for Multiple Models)\n",
    "\n",
    "This notebook:\n",
    "1. Fetches and transforms the value-factor dataset  \n",
    "2. Prepares features `X` and target `y`  \n",
    "3. Defines hyperparameter grids for each model  \n",
    "4. Runs a HalvingGridSearchCV for each (`linear`, `random_forest`, `xgboost`, `gbr`)  \n",
    "5. Plots & saves results automatically  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "from joblib import parallel_backend\n",
    "\n",
    "from fetchers.FetchFactory import FetchFactory\n",
    "from factor_pipeline.registry.TrainerFactory import get_trainer\n",
    "from tuning.Tuner import Tuner\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV, ParameterGrid, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIG & DATA FETCH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"fetchers\": {\n",
    "        \"value\": {\n",
    "            \"clean_missing\": True,\n",
    "            \"frequency\":   \"M\",\n",
    "            \"default_start_date\": \"2020-01-01\",\n",
    "            \"default_end_date\":   \"2026-01-31\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "START_DATE = CONFIG[\"fetchers\"][\"value\"][\"default_start_date\"]\n",
    "END_DATE   = CONFIG[\"fetchers\"][\"value\"][\"default_end_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_fetcher = FetchFactory({}).build_fetchers()[\"sp500\"]\n",
    "tickers = sp_fetcher.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_COLS = [\n",
    "    \"z_price_to_earnings_ratio\",\n",
    "    \"z_price_to_book_ratio\",\n",
    "    \"z_price_to_sales_ratio\",\n",
    "    \"z_price_to_free_cash_flow_ratio\",\n",
    "    \"z_free_cash_flow_yield\",\n",
    "    \"z_earnings_yield\",\n",
    "    \"z_graham_number\",\n",
    "    \"z_return_on_equity\",\n",
    "    \"z_return_on_assets\"\n",
    "]\n",
    "TARGET_COL = \"next_return\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_GRIDS = {\n",
    "    \"linear\": {\n",
    "        \"fit_intercept\": [True, False],\n",
    "        \"positive\":      [True, False],\n",
    "        \"copy_X\":        [True, False],\n",
    "        \"n_jobs\":        [None, -1]\n",
    "    },\n",
    "    \"random_forest\": [\n",
    "        # ── combos WITH bootstrap=True and max_samples options\n",
    "        {\n",
    "            \"n_estimators\":      [50, 100, 200, 500],\n",
    "            \"criterion\":         [\"squared_error\", \"absolute_error\", \"friedman_mse\"],\n",
    "            \"max_depth\":         [5, 10, 20, None],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\":  [1, 2, 4],\n",
    "            \"max_features\":      [None, \"sqrt\", \"log2\", 0.5, 1.0],\n",
    "            \"bootstrap\":         [True],\n",
    "            \"max_samples\":       [None, 0.5, 0.75]\n",
    "        },\n",
    "        # ── combos WITH bootstrap=False (must drop max_samples)\n",
    "        {\n",
    "            \"n_estimators\":      [50, 100, 200, 500],\n",
    "            \"criterion\":         [\"squared_error\", \"absolute_error\", \"friedman_mse\"],\n",
    "            \"max_depth\":         [5, 10, 20, None],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\":  [1, 2, 4],\n",
    "            \"max_features\":      [None, \"sqrt\", \"log2\", 0.5, 1.0],\n",
    "            \"bootstrap\":         [False]\n",
    "        }\n",
    "    ],\n",
    "    \"xgboost\": {\n",
    "        \"n_estimators\":      [50, 100, 200, 500],\n",
    "        \"max_depth\":         [3, 6, 10, 15],\n",
    "        \"learning_rate\":     [0.01, 0.05, 0.1, 0.2],\n",
    "        \"subsample\":         [0.6, 0.8, 1.0],\n",
    "        \"colsample_bytree\":  [0.6, 0.8, 1.0],\n",
    "        \"gamma\":             [0, 1, 5],\n",
    "        \"reg_alpha\":         [0, 0.1, 1],\n",
    "        \"reg_lambda\":        [1, 5, 10],\n",
    "        \"min_child_weight\":  [1, 3, 5]\n",
    "    },\n",
    "    \"gbr\": {\n",
    "        \"loss\":              [\"squared_error\", \"absolute_error\"],\n",
    "        \"learning_rate\":     [0.01, 0.05, 0.1, 0.2],\n",
    "        \"n_estimators\":      [50, 100, 200, 500],\n",
    "        \"max_depth\":         [3, 6, 10, 15],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\":  [1, 2, 4],\n",
    "        \"subsample\":         [0.6, 0.8, 1.0],\n",
    "        \"max_features\":      [None, \"sqrt\", \"log2\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#####  FETCH / PREPROCESS / TUNE / VISUALIZE\n",
    "Load raw data and let the trainer handle all winsorizing, z-scoring, forward returns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_fetcher = FetchFactory(config=CONFIG).build_fetchers()[\"value\"]\n",
    "df = value_fetcher.fetch(tickers, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_fits(n_initial, factor, n_splits):\n",
    "    \"\"\"\n",
    "    Compute total fits across all halving iterations:\n",
    "      sum_{i=0..I} (n_i * n_splits), where n_0 = n_initial,\n",
    "      n_{i+1} = max(1, n_i // factor), stop when n_i == 1.\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    n = n_initial\n",
    "    while True:\n",
    "        total += n * n_splits\n",
    "        if n == 1:\n",
    "            break\n",
    "        n = max(1, n // factor)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tuning_results(df_cv, model_type, grid):\n",
    "    df = df_cv.copy()\n",
    "    df[\"mean_mse\"] = -df[\"mean_test_score\"]\n",
    "\n",
    "    # pick your two “axes” out of the grid\n",
    "    h1, h2 = list(grid.keys())[:2]\n",
    "    p1, p2 = f\"param_{h1}\", f\"param_{h2}\"\n",
    "\n",
    "    # group to get one MSE per (h2, h1)\n",
    "    df_line = (\n",
    "        df\n",
    "        .groupby([p2, p1])[\"mean_mse\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .sort_values([p2, p1])\n",
    "    )\n",
    "\n",
    "    # build a pivot for the heatmap too\n",
    "    pivot = df_line.pivot(index=p2, columns=p1, values=\"mean_mse\")\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # — left: one line per h2 —\n",
    "    for val in pivot.index:\n",
    "        ax1.plot(\n",
    "            pivot.columns.astype(str),\n",
    "            pivot.loc[val].values,\n",
    "            marker=\"o\",\n",
    "            label=f\"{h2}={val}\"\n",
    "        )\n",
    "    ax1.set_title(f\"{model_type} tuning: MSE vs {h1}\")\n",
    "    ax1.set_xlabel(h1)\n",
    "    ax1.set_ylabel(\"Mean CV MSE\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # — right: heatmap of that same pivot —\n",
    "    im = ax2.imshow(pivot.values, aspect=\"auto\")\n",
    "    ax2.set_xticks(range(pivot.shape[1]))\n",
    "    ax2.set_xticklabels(pivot.columns.astype(str), rotation=45, ha=\"right\")\n",
    "    ax2.set_yticks(range(pivot.shape[0]))\n",
    "    ax2.set_yticklabels(pivot.index.astype(str))\n",
    "    ax2.set_title(f\"{model_type} heatmap: {h2} x {h1}\")\n",
    "    ax2.set_xlabel(h1)\n",
    "    ax2.set_ylabel(h2)\n",
    "    fig.colorbar(im, ax=ax2, label=\"Mean CV MSE\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "for model_type, grid in PARAM_GRIDS.items():\n",
    "    trainer = get_trainer(\"value\", model_path=None, model_type=model_type, model_params={})\n",
    "    X, y = trainer.preprocess_data(df.sort_index(), TRAINING_COLS, TARGET_COL)\n",
    "\n",
    "    base_est = Tuner(model_type=model_type, param_grid=grid, cv=4, scoring=\"neg_mean_squared_error\")._make_base_estimator()\n",
    "    tscv     = TimeSeriesSplit(n_splits=4)\n",
    "    factor   = 2\n",
    "\n",
    "    search = HalvingGridSearchCV(\n",
    "        estimator=base_est,\n",
    "        param_grid=grid,\n",
    "        cv=tscv,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        factor=factor,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,          # or >=1 to see per-iteration stats\n",
    "        error_score=np.nan  # silence invalid combos into NaN rather than crash\n",
    "    )\n",
    "\n",
    "    total_fits = compute_total_fits(len(list(ParameterGrid(grid))), factor, tscv.get_n_splits())\n",
    "    with parallel_backend(\"loky\"):\n",
    "        with tqdm_joblib(tqdm(desc=f\"Tuning {model_type}\", total=total_fits, unit=\"fit\")):\n",
    "            search.fit(X, y)\n",
    "\n",
    "    best_params = search.best_params_\n",
    "    df_cv       = pd.DataFrame(search.cv_results_)\n",
    "    all_results[model_type] = {\n",
    "        \"best_params\": best_params,\n",
    "        \"estimator\":   search.best_estimator_,\n",
    "        \"cv_results\":  df_cv\n",
    "    }\n",
    "\n",
    "    print(f\"→ Best for {model_type}: {best_params}\")\n",
    "    plot_grid = grid[0] if isinstance(grid, list) else grid\n",
    "    plot_tuning_results(df_cv, model_type, plot_grid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factor-portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
